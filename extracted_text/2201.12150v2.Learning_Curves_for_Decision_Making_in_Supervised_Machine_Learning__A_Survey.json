{
  "full_text": "Springer Nature 2021 LATEX template\nLearning Curves for Decision Making in\nSupervised Machine Learning: A Survey\nFelix Mohr1* and Jan N. van Rijn2\n1Universidad de La Sabana, Ch´ıa, Cundinamarca, Colombia.\n2Leiden Institute of Advanced Computer Science, Leiden\nUniversity, Leiden, The Netherlands.\n*Corresponding author(s). E-mail(s):\nfelix.mohr@unisabana.edu.co;\nContributing authors: j.n.van.rijn@liacs.leidenuniv.nl;\nAbstract\nLearning curves are a concept from social sciences that has been adopted\nin the context of machine learning to assess the performance of a learn-\ning algorithm with respect to a certain resource, e.g., the number of\ntraining examples or the number of training iterations. Learning curves\nhave important applications in several machine learning contexts, most\nnotably in data acquisition, early stopping of model training, and model\nselection. For instance, learning curves can be used to model the per-\nformance of the combination of an algorithm and its hyperparameter\nconfiguration, providing insights into their potential suitability at an\nearly stage and often expediting the algorithm selection process. Var-\nious learning curve models have been proposed to use learning curves\nfor decision making. Some of these models answer the binary deci-\nsion question of whether a given algorithm at a certain budget will\noutperform a certain reference performance, whereas more complex mod-\nels predict the entire learning curve of an algorithm. We contribute a\nframework that categorises learning curve approaches using three cri-\nteria: the decision-making situation they address, the intrinsic learning\ncurve question they answer and the type of resources they use. We\nsurvey papers from the literature and classify them into this framework.\nKeywords: learning curves, supervised machine learning\n1\narXiv:2201.12150v2  [cs.LG]  28 Jan 2025\n\nSpringer Nature 2021 LATEX template\n2\nLearning Curves for Decision Making\n1 Introduction\nLearning curves describe a system’s performance on a task as a function of\nsome resource to solve that task. There can be a pre-defined budget of that\nresource, limiting the amount of resources that can be spent. In other cases, the\ngoal can be to obtain reasonable results while minimising the spent budget of\nthat resource. Typical types of budgets are the number of examples the learner\nhas observed before performing the task or the number of iterations or time\nthe learner spends in an environment. The performance measure expresses the\nquality of the obtained model, e.g., error rate or F1 measure. Learning curves\nare an important source of information for making decisions on the following\nmatters in machine learning:\n• Data Acquisition determines how many data points should reasonably be\nacquired to obtain a desired performance. The top right plot in Fig. 1 visu-\nalises a scenario where we have already observed performance up to a certain\namount of data (the blue learning curve). We can extrapolate this and make\na prediction of what the performance would be if more data was available,\ni.e., the value of the orange extrapolation at different vertical pink lines in\nthe figure (see, e.g., Last, 2009; Weiss and Tian, 2008).\n• Early Stopping of training a model. If we are committed to some specific\nlearner (a learning algorithm and its hyperparameters), we might want to\nminimise the training time (John and Langley, 1996; Provost et al, 1999)\nor avoid over-fitting (Bishop, 1995; Goodfellow et al, 2016). The middle\nright plot in Fig. 1 visualises a scenario where we have already observed\nperformance up to a certain amount of budget, and based on the progression\nof the learning curves on recent iterations, a decision can be made whether\nto continue the learning or terminate it.\n• Early Discarding in model selection. If we want to select from various mod-\nels, we want to stop the evaluation of a candidate when we are reasonably\ncertain that it is not competitive to the best-known solution (Domhan et al,\n2015; Mohr and van Rijn, 2023; Swersky et al, 2014). The bottom right plot\nof Fig. 1 visualises a scenario where we have already observed performance\nup to a certain amount of budget (the blue learning curve) and already\nan incumbent performance obtained by an earlier configuration (horizon-\ntal dashed pink line). By using learning curve extrapolation techniques, we\ncan determine whether the current configuration can surpass the incumbent\nconfiguration; if not, discarding the current training process early (as in the\ncase shown) would be justified.\nMany techniques with varying complexity and required resources have been\nproposed to address either of these problems. The complexity ranges from\napproaches that simply recognise whether an already observed part of a learn-\ning curve has converged (Bishop, 1995; Provost et al, 1999) to the creation\nof parametric learning curve models, which capture a belief model for the\nbehaviour of various learners at any possible budget (Klein et al, 2017b). While\nsimple approaches may only rely on the observations made so far for a learner\n\nSpringer Nature 2021 LATEX template\nLearning Curves for Decision Making\n3\nFig. 1: The three types of decision-making situations in which learning curves\nare typically used. The x-axis of each figure represents the budget in the appli-\ncable unit, and the y-axis represents the performance.\non the dataset of interest, more complex approaches may rely on additional\nresources such as learning curves or features of other datasets (see, e.g., Leite\nand Brazdil, 2010) or learners (see, e.g., Chandrashekaran and Lane, 2017) or\nboth (see, e.g., Ruhkopf et al, 2023).\nOur contribution is a unified framework of the usage of learning curves for\ndecision making in machine learning and an extensive review of the literature\nof approaches that fall within this framework. This framework categorises the\nexisting literature along the following three axes:\n1. The type of decision-making situation, i.e., whether it is used to make\ndecisions about data acquisition, early stopping, or early discarding. See\nSec. 4.1 for more details.\n2. The type of technical question that can be answered with an approach,\ne.g., some approaches can only answer the binary question whether a\nmodel has converged, whereas other approaches are able to answer ques-\ntions about the behaviour of any part of the learning curve. See Sec. 4.2\nfor more details.\n3. The data resources that are used to model the learning curve. For exam-\nple, in some cases, data from different algorithms on the same dataset\nis being used, whereas in other cases, data from the same algorithm on\nother datasets. See Sec. 4.3 for more details.\nWe perform an extensive literature survey in which we categorise published\nlearning curve extrapolation models along the various axes of this framework.\nThis literature survey is subject of Sec. 5, which is then summarised in Table 1.\nWe focus specifically on supervised machine learning, in which learning curves\ndescribe the predictive performance of a model produced by a learning algo-\nrithm either as a function of the number of training instances or of the time or\niterations spent for learning on a given dataset. We explicitly exclude learning\n\nSpringer Nature 2021 LATEX template\n4\nLearning Curves for Decision Making\ncurves that describe the performance of a learning agent in an environment\nover time, i.e., the learning curve of an agent in a reinforcement learning\nsetup (Waltz and Fu, 1965). Similarly, we briefly contrast learning curves to\nother performance curves, such as active learning curves, feature curves, and\ncapacity curves, and explain why we consider these out of scope for the litera-\nture review. Still, we aim to survey exhaustively the literature that introduces\napproaches that use learning curves in supervised learning.\nContributions:\nOur contributions are the following.\n• We present a unified framework of the usage of learning curves for decision\nmaking in machine learning and an extensive review of the literature on\napproaches that fall within this framework. This framework contains three\naxes, i.e., (i) the type of decision-making situation, see also Fig. 1 (ii) the\ntype of question that can be answered, see also Fig. 10 and (iii) the data\nresources that are used to model the learning curve, see also Fig. 11. While\nthe first axis of this framework is also used in other literature (see, e.g.,\nViering and Loog, 2023), to the best of our knowledge, the other two axes\nhave not yet been explicitly identified.\n• We conducted a literature survey in which we categorise methods presented\nin the literature along the various axes of this framework. Sec. 5 lists all\nthese methods (where each subsection represents a type of question being\nanswered), and Table 1 overviews all methods along the three axes of our\nframework.\n• Based on the framework, we identify unexplored routes for further research.\nMost notably, we note that there is a mismatch between the research ques-\ntions being answered and the learning curve modelling method being used;\nin many cases, a high-level modelling technique is used to answer a low-\nlevel question. We speculate that matching the level of the question being\nanswered with the appropriate level of the modelling technique can further\nimprove the obtained results.\nRelation to other literature reviews on learning curves:\nAnother prominent literature review that centres around learning curves is\nthe highly complementary work by Viering and Loog (2023), which has been\ndeveloped in parallel. While both works have identified the three types of\ndecision-making situations that are referred to in the literature, Viering and\nLoog (2023) survey more theoretical work that analyses the shape of learning\ncurves, whereas this work surveys work that is more oriented towards methods\nthat extrapolate learning curves, thereby supporting the data scientists in\nvarious decision-making situations.\nStructure:\nThis paper is structured into three main parts. Sec. 2 presents relevant back-\nground knowledge on learning curves, including formal definitions and the\n\nSpringer Nature 2021 LATEX template\nLearning Curves for Decision Making\n5\nterminology relevant for the remainder. Sec. 3 presents relevant important con-\ncepts that relate to how learning curves are generally modelled. Sec. 4 contains\nour main contribution by introducing our framework for categorising methods\nthat utilise learning curves for decision making in supervised learning. Follow-\ning this framework, Sec. 5 exhaustively reviews approaches that explicitly or\nimplicitly answer questions related to learning curves to make or recommend\ndecisions in the context of supervised machine learning. Sec. 6 concludes our\nfindings. Finally, Appendix A presents a table that overviews the most critical\nnotation used throughout this paper.\n2 Background on Learning Curves\nThis section gives a conceptual background on learning curves. It first provides\nan idealised formal definition in Sec. 2.1 followed by a definition of empirical\nlearning curves in Sec. 2.2 that can be computed in practice. The concept of\nutility curves is introduced in Sec. 2.3. Sec. 2.4 introduces important terminol-\nogy such as anchor points, limit performance, and the saturation point. Finally,\nSec. 2.5 contrasts the learning curves covered in this survey with other types\nof performance curves used in machine learning.\n2.1 Sample-Wise and Iteration-Wise Learning Curves\nWe consider learning curves in the context of supervised machine learning.\nFormally, in the supervised learning context, we assume some instance space\nX and a label space Y. A dataset d ⊂{(x, y) | x ∈X, y ∈Y} is a finite\nrelation between the instance space and the label space. We denote as D the\nset of all possible datasets. A learning algorithm is a function a : D × Ω→H ,\nwhere H = {h | h : X →Y} is the space of hypotheses and Ωis a source of\nrandomness.\nNote that learning curves can also be considered in other machine learning\nsetups. In fact, learning curves appeared first in reinforcement learning (Waltz\nand Fu, 1965) and have also been used for unsupervised learning (Meek et al,\n2002). However, to give this survey focus, we consider learning curves for\nsupervised learning.\nThe performance of a hypothesis is typically expressed as risk, which is\nalso often called out-of-sample error:\nRout(h) =\nZ\nX,Y\nloss(y, h(x)) dPX×Y.\n(1)\nHere, loss(y, h(x)) ∈R is the penalty for predicting h(x) for instance x ∈X\nwhen the true label is y ∈Y, and PX×Y is a joint probability measure on\nX × Y from which the available dataset d has been generated. As such, the\nout-of-sample error represents the weighted summed error that hypothesis h\nmakes on all possible instance-label pairs, weighted by their probabilities.\n\nSpringer Nature 2021 LATEX template\n6\nLearning Curves for Decision Making\nThe performance of a learning algorithm is simply the performance of the\nhypothesis it produces. In contrast to the performance of a hypothesis, the\nperformance of a learner depends on its input, i.e., on the data provided for\nlearning. The average performance of learner a for a number n of training\nexamples can then be expressed as\nC(a, n) =\nZ\nω∈Ω,dtr∈D,|dtr|=n\nRout(a(dtr, ω))dPX×YdPΩ,\n(2)\nwhere dtr ∈D is the dataset of size n used to induce a model using learner a.\nIt is generally assumed that d is a collection of i.i.d. samples from PX×Y.\nWhen we consider Eq. (2) as a function of the number of training samples\nfor a fixed learner a, we obtain the sample-wise curve of learner a. That is,\nthe sample-wise curve is the function C(a, ·) : N →R; so it is a sequence of\nperformances, one for each training size. Fig. 2 (left) visualises this by means\nof the green line and compares this to two other types of learning curves with\nthe error rate as the loss (see Sec. 2.5).\nAlternatively, many learning algorithms implement an iterative internal\noptimisation process, which allows describing the learning progress over time\nor a number of iterations. For example, neural network training produces a\nnew hypothesis after every batch or epoch, ensemble learners like bagging\nor boosting produce a new hypothesis after every added ensemble member,\nand support vector machine optimizers yield updated attribute or instance\ncoeffients in iteration. In the formal framework, a learner can be seen more\ngenerally as a function a : D × Ω→H + that maps a dataset to a sequence of\nhypotheses, one for each of its iterations. The above error function for learners\ncan then be written as\nC(a, n, t) =\nZ\nω∈Ω,dtr∈D,|dtr|=n\nRout(a(dtr, ω)t)dPX×YdPΩ,\n(3)\nHere, t expresses some budget, for example, time or a number of iterations\nover the dataset, often expressed in epochs.\nBased on this notion, the iteration-wise curve of a learner a is defined for a\nfixed dataset size n (often between 70% and 90% of the available data) and is\nthen the function C(a, n, ·) : N →R. Fig. 2 (right) visualises an example of two\niteration-wise curves. It can be seen that these it"
}