{
  "abstract": "‚ÄîAlthough lyrics represent an essential component\nof music, few music information processing studies have been\nconducted on the characteristics of lyricists. Because these\ncharacteristics may be valuable for musical applications, such\nas recommendations, they warrant further study. We considered\na potential method that extracts features representing the char-\nacteristics of lyricists from lyrics. Because these features must\nbe identified prior to extraction, we focused on lyricists with\neasily identifiable features. We believe that it is desirable for\nsingers to perform unique songs that share certain characteristics\nspecific to the singer.",
  "introduction": "As an integral component of music, lyrics significantly\ninfluence the overall impression of a song. Although many\nstudies have been conducted on the use of lyrics for song\nrecommendation and song trend prediction tasks, lyricists have\nnot received as much research attention as singers. One area of\ninterest is authorship classification, which entails identifying\nthe author of a text using the text itself as a source of\ninformation. Potential applications of authorship classification\ntechniques include the identification of anonymous authors, as\nwell as the prediction of attributions of criminals who issue\nanonymous threats.\nBecause lyrics are creative works authored by lyricists, we\nbelieve that the characteristics of lyricists can be leveraged in\nCharacteristics \nof Singer\nCharacteristics \nof Lyricist\nLyrics\nTheme of Song\nFig. 1.",
  "related_work": "A. Authorship Classification\nAuthorship classification [2], the classification of authors\nfrom their texts, has been an objective of numerous studies.\nOne approach to this task is to focus on unique textual\nexpressions, also known as idiolect. Mael et al. [3] proposed\na BERT-based authorship ensemble classification model that\ncombines outputs from logistic regression models utilizing\nstylometric features based on econometric literature concepts,\nas well as hybrid features calculated from N-grams. Dhar\n[4] developed an authorship classification system using a\nconvolutional neural network (CNN), which processes natural\nlanguage sentences by converting them into sentence vectors\nprior to feature extraction and classification.",
  "methodology": "have been proposed.\nVelankar et al. [8] analyzed Hindi lyrics written in a script\ncalled Devanagari by defining five moods. Corbara et al. [9]\nclassified genres and artists by incorporating information from\nthe Billboard magazine, including the durations and rankings\nof songs published in the magazine. Haraguchi et al.",
  "results": ". First, we grouped\nlyricists among five groups in terms of lyricist-singer entropy and\nassessed the lyric-lyricist classification performance within each\ngroup. Subsequently, we statistically evaluated the relationship\nbetween lyricist-singer entropy and lyric-lyricist classification\nperformance, finding a weak negative correlation that supports\nour hypothesis. Specifically, the best F1 score was obtained for the\ngroup with the lowest lyricist-singer entropy. Our results suggest\nthat further analyses of the features contributing to lyric-lyricist\nclassification performance on the lowest lyricist-singer entropy\ngroup may improve the feature extraction task for lyricists.\nIndex Terms‚Äîlyric-lyricist classification, lyricist-singer en-\ntropy, lyric analysis, BERT\nI.",
  "discussion": "We analyzed the relationship between lyricist-singer entropy\nand lyric-lyricist classification performance, where the former\nis a measure of singer diversity for an individual lyricist, and\nthe latter is calculated through the lyric-lyricist classification\ntask defined in this study. We found a negative correlation\n\n0.2\n0.4\n0.6\n0.8\ne0\ne1\ne2\ne3\ne4\nHomogenous sampling\nPrecision\nRecall\nF1\nùê¥‚àó\nùê¥\"\nùê¥ $ \nùê¥% \nùê¥& \nùê¥' \nFig. 4. Classification performance on homogenous sampling A‚àó\n0.2\n0.4\n0.6\n0.8\ne0\ne1\ne2\ne3\ne4\nHomogenous sampling\nPrecision\nRecall\nF1\nùêµ‚àó\nùê¥\"\nùê¥ $ \nùê¥% \nùê¥& \nùê¥' \nFig. 5.",
  "conclusion": "This study was conducted to examine how lyricist-singer\nentropy affects lyric-lyricist classification performance. We\nfound that lyricists with a lower lyricist-singer entropy tend to\nbe easier to classify, and lyricists with a lyricist-singer entropy\nof 0 are significantly easier to classify. We conducted lyric-\nlyricist classification experiments to evaluate the relationship\nbetween lyricist-singer entropy and lyric-lyricist classification\nperformance. Our hypothesis states that classifying lyrics with\ndifferent singers to the same lyricist is more challenging\nthan classifying the lyrics of one singer to the same lyricist.\nThe experimental results demonstrate weak support for our\nhypothesis. Further analysis of lyrics written by lyricists with\na lyricist-singer entropy of zero may be promising in inter-\npreting the features contributing to lyric-lyricist classification\nperformance.\nACKNOWLEDGMENT\nThis work was supported in part by JSPS KAKENHI Grant\nNumbers JP19K12266, JP22K18006.\nTABLE IV\nLYRIC-LYRICIST CLASSIFICATION PERFORMANCE\nON HETEROGENOUS SAMPLING A‚àó\nPrecision\nRecall\nF1\nA0\n0.769\n0.760\n0.733\nA1\n0.722\n0.705\n0.682\nA2\n0.727\n0.690\n0.677\nA3\n0.656\n0.715\n0.658\nA4\n0.700\n0.665\n0.653\nTABLE V\nLYRIC-LYRICIST CLASSIFICATION PERFORMANCE\nON HETEROGENOUS SAMPLING B‚àó\nPrecision\nRecall\nF1\nB0\n0.761\n0.755\n0.728\nB1\n0.626\n0.600\n0.582\nB2\n0.662\n0.695\n0.645\nB3\n0.671\n0.660\n0.628\nB4\n0.540\n0.510\n0.497",
  "references": "[1] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.\nBERT: Pre-training of deep bidirectional transformers for language\nunderstanding.\nIn Proceedings of the 2019 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, volume 1, pages 4171‚Äì4186, 2019.\n[2] Wanwan Zheng and Mingzhe Jin. A review on authorship attribution in\ntext mining. WIREs Conputational Statistics, 15(2):1‚Äì23, 2023.\n[3] Ma¬®el Fabien, Esau Villatoro-Tello, Petr Motlicek, and Shantipriya\nParida.\nBertAA : BERT fine-tuning for authorship attribution.\nIn\nProceedings of the 17th International Conference on Natural Language\nProcessing (ICON), pages 127‚Äì137, 2020.\n[4] Ankita Dhar, Himadri Mukherjee, Shibaprasad Sen, Md Obaidullah\nSk, Amitabha Biswas, Teresa Gonc¬∏alves, and Kaushik Roy.\nAuthor\nidentification from literary articles with visual features: A case study\nwith bangla documents. Future Internet, 14(10):1‚Äì20, 2022.\n[5] Yunita Sari, Mark Stevenson, and Andreas Vlachos.\nTopic or style?\nexploring the most useful features for authorship attribution. In Proceed-\nings of the 27th International Conference on Computational Linguistics,\npages 343‚Äì353, 2018.\n[6] Anastasia Fedotova, Aleksandr Romanov, Anna Kurtukova, and Alexan-\nder Shelupanov.\nDigital authorship attribution in russian-language\nfanfiction and classical literature."
}