{
  "abstract": ". The following brieﬂy discusses possible diﬃculties in com-\nmunication with and control of an AGI (artiﬁcial general intelligence),\nbuilding upon an explanation of The Fermi Paradox and preceding work\non symbol emergence and artiﬁcial general intelligence. The latter sug-\ngests that to infer what someone means, an agent constructs a rationale\nfor the observed behaviour of others. Communication then requires two\nagents labour under similar compulsions and have similar experiences\n(construct similar solutions to similar tasks).",
  "methodology": "",
  "results": "",
  "conclusion": ""
}