{
  "abstract": "— A Human Computer Interface (HCI) \nSystem for playing games is designed here for \nmore natural communication with the machines. \nThe system presented here is a vision-based \nsystem for detection of long voluntary eye blinks \nand \ninterpretation \nof \nblink \npatterns \nfor \ncommunication between man and machine. This \nsystem replaces the mouse with the human face \nas a new way to interact with the computer. \nFacial features (nose tip and eyes) are detected \nand tracked in real-time to use their actions as \nmouse events. The coordinates and movement of \nthe nose tip in the live video feed are translated \nto become the coordinates and movement of the \nmouse pointer on the application.",
  "introduction": "One \nof \nthe \npromising \nfields \nin \nartificial \nintelligence is HCI. Human-Computer Interface \n(HCI) \ncan \nbe \ndescribed \nas \nthe \npoint \nof \ncommunication between the human and a computer. \nHCI aims to use human features to interact with the \ncomputer. The system tracks the computer user's \nmovements with a video camera and translates them \ninto the movements of the mouse pointer on the \nscreen. The tip of the user's nose can be tracked and \ncaptured with a webcam and monitor its movements \nin order to translate it to some events that \ncommunicate with the computer.",
  "related_work": "With the growth of attention about computer \nvision, \nthe \ninterest \nin \nHCI \nhas \nincreased \nproportionally. Different human features and \nmonitoring devices were used to achieve HCI, but \nduring our research we were only into works that \ninvolved the use of facial features and webcams. \nThe current evolution of computer technologies \nhas enhanced various applications in human-\ncomputer interface. Face and gesture recognition is \na part of this field, which can be applied in various \napplications such as in robotic, security system, \ndrivers monitor, and video coding system. \nWe noticed a large diversity of the facial features \nthat were selected, the way they were detected and \ntracked, and the functionality that they presented for \nthe HCI.",
  "methodology": "used \nexpensive \nequipments, some were not fast enough to achieve \nreal-time execution, and others were not robust and \nprecise enough to replace the mouse. We tried to \nprofit from the experience that other researchers \ngained in the HCI field and added our own ideas to \nproduce an application that is fast, robust, and \nuseable. \n   Eye movement events detected in EOG signals \nsuch as saccades, ﬁxations and blinks have been \nused to control robots or a wearable system for \nmedical care givers. Patmore et al. described a \nsystem that provides a pointing device for people \nwith physical disabilities.",
  "results": "with \nless processing time. To control the mouse pointer \nvarious points were tracked ranging from the middle \ndistance between the eyes, the middle distance \nbetween the eyebrows, to the nose tip. To simulate \nmouse clicks; eye blinks, mouth opening/closing, \nand sometimes eyebrow movement were used. Each \nHCI method that we read about had some \ndrawbacks, \nsome \nmethods \nused \nexpensive \nequipments, some were not fast enough to achieve \nreal-time execution, and others were not robust and \nprecise enough to replace the mouse. We tried to \nprofit from the experience that other researchers \ngained in the HCI field and added our own ideas to \nproduce an application that is fast, robust, and \nuseable.",
  "discussion": "",
  "conclusion": "The proposed system is the best system for the \nusers to play games interactively. The automatic \ninitialization phase is greatly simpliﬁed in this \nsystem, with no loss of accuracy in locating the \nuser’s eyes and choosing a suitable open eye \ntemplate. Another improvement in this system is, it \nis compatible with inexpensive USB cameras, as \nopposed to the high- resolution cameras. The \nexperiments indicate that the system performs \nequally well in extreme lighting conditions. The \naccuracy percentages in all the cases were \napproximately the same as those that were retrieved \nin normal lighting conditions.",
  "references": "as shown in Fig.1. \n               sr = (ii (x ,y ) + ii(x - W, y - L)) - (ii (x - W, \ny) +  ii(x, y - L ))                                                    (4) \n \n \n \nFigure 1. Integral Image \n2) SSR filter  \nAt the beginning, a rectangle is scanned throughout \nthe input image. This rectangle is segmented into \nsix segments as shown in Fig.2 (a). \n \nFigure 2."
}