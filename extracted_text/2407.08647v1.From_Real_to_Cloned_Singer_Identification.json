{
  "abstract": "Cloned voices of popular singers sound increasingly re-\nalistic and have gained popularity over the past few years.\nThey however pose a threat to the industry due to personal-\nity rights concerns. As such,",
  "introduction": "In April 2023, the track “Heart on my Sleeve” by an anony-\nmous TikTok user Ghostwriter977 put the music industry\nin a frenzy [1,2]. The artist used artificial intelligence (AI)\nbased cloning technologies to turn their voice into Drake\nand the Weeknd’s [3], two of the most popular singers in\nthe world. The song became very popular across music\nstreaming platforms, before being removed by demand of\nthe original artists’ right owners. This situation raised the\nneed for singer identification systems that can also identify\nthe original singer a synthetic voice was generated from.\nIn this paper, we train three embedding models for\nsinger identification using a singer-level contrastive learn-\ning scheme, where positive pairs consist of segments with\nvocals of the same singers whilst negatives come from dif-\nferent singers. These samples can be mixtures for the first\nmodel, vocals for the second, and both for the third.",
  "related_work": "Singer identification, has been a staple of the music infor-\nmation retrieval (MIR) community for more than twenty\nyears [7, 8]. Early approaches aimed to attenuate the in-\nstrumental parts of a song through the use of vocal melody\nor pitch extraction and voice re-synthesis and detection al-\ngorithms [9–11]. Classic features, such as mel-frequency\ncepstral coefficients (MFCCs), were then computed on\nthese signals and used as inputs for a classifier. The im-\nprovements in music source separation [12,13] then led re-\n1 https://github.com/deezer/real-cloned-singer-id\n  [cs.SD]  11 Jul 2024\n\nsearchers to build models that classify singers using the vo-\ncals of each song [14, 15]. More recently, self-supervised",
  "methodology": "to identify the orig-\ninal singer in synthetic voices are needed. In this paper,\nwe investigate how singer identification methods could be\nused for such a task. We present three embedding mod-\nels that are trained using a singer-level contrastive learning\nscheme, where positive pairs consist of segments with vo-\ncals from the same singers. These segments can be mix-\ntures for the first model, vocals for the second, and both\nfor the third. We demonstrate that all three models are\nhighly capable of identifying real singers.",
  "results": "for reproducibility purposes. Note that four\nsegments from each validation track are selected randomly\nat the beginning of each singer identification experiment\nto keep the validation set constant. At least three tracks\nper singer are then used for training. During each training\niteration, we select a segment with vocals on the fly to con-\nstruct batches of size 100. We minimize a Cross Entropy\nloss [36] using the ADAM optimizer with an initial learn-\ning rate of 0.01.",
  "discussion": "",
  "conclusion": "In this paper, we train three models using singer-level con-\ntrastive learning. The first is only trained using mixtures,\nthe second is only trained using vocal stems, while the\nthird is trained using both. We find that all three mod-\nels are highly capable of classifying real singers, though\nthere remain open challenges, such as classifying genres\nthat use more vocal effects and singers with long discogra-\nphies. However, all three models’ performance decreases\ndrastically when trying to identify cloned voices of ex-\nisting singers. This decrease is much more pronounced\nfor models that are trained using mixtures.",
  "references": "[1] J. Coscarelli, “An a.i. hit of fake ‘drake’ and ‘the\nweeknd’ rattles the music world,” The New York Times.\n[Online]. Available: https://www.nytimes.com/2023/0\n4/19/arts/music/ai-drake-the-weeknd-fake.html\n[2] H. H."
}