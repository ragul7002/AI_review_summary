{
  "abstract": "Modern biology frequently relies on machine learning to provide predictions and improve decision\n \n \n \n \n \n \n \n \n \n \n \n \n \nprocesses. There have been recent calls for more scrutiny on machine learning performance and possible\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nlimitations. Here we present a set of community-wide recommendations aiming to help establish\n \n \n \n  \n \n \n \n \n \n \n \n \nstandards of supervised machine learning validation in biology. Adopting a structured",
  "introduction": "With the steep decline in the cost of high-throughput technologies, large amounts of biological data are\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nbeing generated and made accessible to researchers. Machine learning (ML) has been brought into the\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nspotlight as a very useful approach to understand cellular​1​, genomic​2​, proteomic​3​, post-translational​4​,\n \n  \n \n \n \n \n \n \n \n \n \nmetabolic​5 and drug discovery data​6 with the potential to result in ground-breaking medical\n \n \n \n \n \n \n \n \n \n \n \n \n \napplications​7,8​. This is clearly reflected in the corresponding growth of ML publications (Figure 1),\n \n \n \n \n \n \n \n \n \n \n \n \n \n \nreporting a wide range of modelling techniques in biology. While every novel ML method should be\n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nvalidated experimentally, this happens only in a fraction of the publications​9​. This sharp increase in\n \n \n \n \n \n  \n \n \n \n \n \n \n \n \npublications inherently requires a corresponding increase in the number and depth of peer-reviews to\n \n \n  \n \n \n \n \n \n \n \n \n \n \noffer critical assessment​10​ and improve reproducibility​11,12​.",
  "related_work": "",
  "methodology": "description for machine learning based on data, optimization, model, evaluation (DOME) will aim to help\n \n \n \n \n \n \n \n \n \n \n \n \n  \n \nboth reviewers and readers to better understand and assess the performance and limitations of a method\n \n \n \n \n \n \n \n \n \n \n \n \n \n  \n \nor outcome. The recommendations are formulated as questions to anyone wishing to pursue\n \n \n \n \n \n \n \n \n \n \n \n \n \nimplementation of a machine learning algorithm. Answers to these questions can be easily included in the\n \n  \n \n \n \n  \n \n \n \n \n \n  \n \nsupplementary material of published papers. \n \nIntroduction  \nWith the steep decline in the cost of high-throughput technologies, large amounts of biological data are\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nbeing generated and made accessible to researchers. Machine learning (ML) has been brought into the\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nspotlight as a very useful approach to understand cellular​1​, genomic​2​, proteomic​3​, post-translational​4​,\n \n  \n \n \n \n \n \n \n \n \n \nmetabolic​5 and drug discovery data​6 with the potential to result in ground-breaking medical\n \n \n \n \n \n \n \n \n \n \n \n \n \napplications​7,8​.",
  "results": "and predictions​13,14​. In the biomedical research field, communities have defined standard\n \n \n \n \n \n \n \n \n \n \n \n \n \nguidelines and best practices for scientific data management​15 and reproducibility of computational\n \n \n \n \n \n \n \n \n \n \n \n \ntools​16,17​. On the other hand, a demand exists in the ML community for a cohesive and combined set of\n \n \n \n \n  \n \n \n \n \n \n \n  \n \n \n \n \n \n1 \n\nrecommendations with respect to data, the optimization techniques, the final model, and evaluation\n \n \n \n \n \n \n \n \n \n \n \n \n \nprotocols as a whole. \n \n \nFigure 1. ​Exponential increase of ML publications in biology.",
  "discussion": "in the wider ML community leading to future\n \n \n \n  \n \n  \n \n \n \n \n \n \n \n \n \nwork addressing possible solutions. \nSeveral key issues related to reproducibility (e.g. data is not published, data splits are not reported and\n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \n \nmodel source code with its final parameters and hyperparameters are not released) can be aided by a\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \nmultitude of workflow systems that help to ensure and automate multi-step processes are completely\n \n \n \n \n \n \n \n \n \n \n \n \n \n \nreproducible by tracking model parameters and exact versions of the source code and libraries. Examples\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nof commonly used workflows include Galaxy​36 and Nextflow​37 . Another ​de facto standard practice in\n \n \n \n \n \n \n \n  \n \n \n \n \n \n \nsoftware engineering is using version control systems such as Github to create an online copy of the\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nsource code, which can also include parameters and documentation.",
  "conclusion": "9 \n\nThe objective of our recommendations is to increase the transparency and reproducibility of ML methods\n \n \n \n \n   \n \n \n \n \n \n \n \n \nfor the reader, the reviewer, the experimentalist, and the wider community. We recognize that these\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nrecommendations are not exhaustive and should be viewed as a consensus-based first iteration of a\n \n \n \n \n \n \n \n \n  \n \n \n \n  \ncontinuously evolving system of community self-review. One of the most pressing issues is to agree to a\n \n \n \n \n \n \n \n \n \n \n \n   \n   \nstandardized data structure to describe the most relevant features of the ML methods being presented. As\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \na first step to address this issue, we recommend including an “ML summary table”, derived from Box 1,\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  \nin future ML studies (see Supplementary Material). We recommend including the following sentence in\n \n \n \n \n \n \n \n \n \n \n \n \n \n \nthe methods section of all papers: “To increase the reproducibility of the machine learning method of this\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nstudy, the machine learning summary table (Table X) is included in the supporting information as per\n \n \n \n \n \n \n \n  \n \n \n \n \n \n \n \nconsensus guidelines (with reference to this manuscript).”  \nThe development of a standardized approach for reporting ML methods has major advantages in\n \n \n  \n \n \n \n \n \n \n \n \n \n \nincreasing the quality of publishing ML methods.",
  "references": "1.\nBaron, C. S. ​et al.​ Cell Type Purification by Single-Cell Transcriptome-Trained Sorting. ​Cell ​179​, \n527-542.e19 (2019). \n2.\nLibbrecht, M."
}