{
  "abstract": ".\nThis white paper describes the LSST Dark Energy Science Collaboration (DESC), whose goal is\nthe study of dark energy and related topics in fundamental physics with data from the Large\nSynoptic Survey Telescope (LSST). It provides an overview of dark energy science and describes\nthe current and anticipated state of the ﬁeld. It makes the case for the DESC by laying out a\nrobust analytical framework for dark energy science that has been deﬁned by its members and\nthe comprehensive three-year work plan they have developed for implementing that framework.\nThe analysis working groups cover ﬁve key probes of dark energy: weak lensing, large scale\nstructure, galaxy clusters, Type Ia supernovae, and strong lensing. The computing working\ngroups span cosmological simulations, galaxy catalogs, photon simulations and a systematic\nsoftware and computational framework for LSST dark energy data analysis. The technical\nworking groups make the connection between dark energy science and the LSST system.",
  "introduction": "and overview . . . . .",
  "related_work": "",
  "methodology": "and cosmological\nparameter estimation. The white paper describes several high priority tasks identiﬁed by each of\nthe 16 working groups. Over the next three years these tasks will help prepare for LSST analysis,\nmake synergistic connections with ongoing cosmological surveys and provide the dark energy\ncommunity with state of the art analysis tools. Members of the community are invited to join the\nDESC, according to the membership policies described in the white paper. Applications to sign\nup for associate membership may be made by submitting the Web form at\nhttp://www.slac.stanford.edu/exp/lsst/desc/signup.html with a short statement of the\nwork they wish to pursue that is relevant to the DESC.\n\nContents\nLSST as a Dark Energy Experiment\n.",
  "results": "in a useful form for a broad community of users are\nmajor challenges. The data management system is conﬁgured in three levels: an infrastructure layer\nconsisting of the computing, storage, and networking hardware and system software; a middleware\nlayer, which handles distributed processing, data access, user interface and system operations\nservices; and an applications layer, which includes the data pipelines and products and the science\ndata archives.\nThe application layer is organized around the data products being produced. The nightly pipelines\nare based on image subtraction, and are designed to rapidly detect interesting transient events in\nthe image stream and send out alerts to the community within 60 seconds of completing the image\nreadout. The data release pipelines, in contrast, are intended to produce the most completely\nanalyzed data products of the survey, in particular those that measure very faint objects and cover\n\n1.3 Planned survey strategy and delivered data products\nlong time scales. A new run will begin each year, processing the entire survey data set that is\navailable to date.",
  "discussion": ", including optical design, the ﬁlter complement, the focal plane\nlayout, and special science programs, please see the LSST overview paper (Ivezic et al. 2008) and\nthe LSST Science Book3 (Abell et al. 2009).\n1.3 Planned survey strategy and delivered data products\nThe LSST observing strategy is designed to maximize scientiﬁc throughput by minimizing slew\nand other downtime and by making appropriate choices of the ﬁlter bands given the real-time\nweather conditions. The fundamental basis of the LSST concept is to scan the sky deep, wide,\nand fast, and to obtain a dataset that simultaneously satisﬁes the majority of the science goals.\nThis concept, the so-called “universal cadence”, will yield the main deep-wide-fast survey and use\nabout 90% of the observing time. The observing strategy for the main survey will be optimized for\nhomogeneity of depth and number of visits.",
  "conclusion": "s or analysis based upon the\nmocks valid. This also requires a detailed understanding of the biases present within all of the\nobservational data sets (5.9.2).\nMock catalogs currently used within the LSST collaboration have focused on reproducing the distri-\nbutions and properties of astrophysical sources that signiﬁcantly impact the technical performance\nof the project Connolly et al. (2010). This ﬁdelity is designed to match the gross properties of the\nsurvey: the distributions of galaxy and stellar magnitudes, the redshift distributions, and the size\ndistributions. To accomplish this, extragalactic catalogs have been derived from the semi-analytic\nmodels of De Lucia et al.",
  "references": ". . . . ."
}